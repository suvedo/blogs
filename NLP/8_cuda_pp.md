[*<<返回主页*](../index.md)<br><br>
**本文为作者原创，转载请注明出处**<br>
### CUDA并行计算
本文叙述性的讲解cuda并行编程相关原理，可以看着是cuda编程的总结和提炼；<br><br>
#### GPU及CUDA概述
gpu是一种插入式卡，是cpu的一个协处理器，早期的gpu主要专注于浮点运算，作为cpu的补充，用于游戏等应用中，后来人们意识到gpu可以用于科学计算，因此出现了GPGPU以及CUDA；<br><br>
gpu板卡主要由五部分组成：1）负责所有计算的gpu芯片，2）gpu内存（显存，与cpu的DRAM相似），3）PCI接口芯片，4）电源芯片，5）使这些芯片能一起工作的其它半导体芯片；
gpu计算芯片与cpu芯片在体系架构上有很大不同，主要体现在：1）gpu核心更多，一般可以达到几百几千个核心，而cpu核心较少，一般只有几个或者几十个，gpu能获得更好的并发性，且gpu启动线程的开销远小于cpu，2）gpu核心的工作频率更低，且结构更加简单，更低的工作频率可以使得gpu芯片获得更低的功耗性能（功耗与频率的平方成正比），简单的结构使得gpu核心可以获得更小的面积；<br><br>
并行程序开发者可以通过cuda编程模型开发并行计算程序，cuda程序同时包含cpu端(主机端)代码和gpu端(设备端)代码，cpu端代码一般负责串行逻辑部分，gpu端代码一般负责并行逻辑部分；
cpu端代码和gpu端代码虽然运行在不同的硬件设备上（甚至两种硬件具有不同的架构和ISA），但cuda允许开发者使用相同的编程语言和语法分别为cpu和gpu编程，甚至将两者放在同一份源文件中，只用一些关键字来区分两者（如，使用__global__关键字标识的函数是设备端函数，在cuda中称为核函数），
并且只需要使一个编译器nvcc即可同时完成主机端和设备端代码的编译，nvcc能识别主机端代码和设备端代码，并将主机端代码编译成x86指令（针对x86架构处理器），将设备端代码编译成PTX指令（针对NV GPU），需要理解的是，x86指令是一种完全编译的机器指令，即这些指令可以直接在硬件上（如，x86cpu）运行，
而PTX只是一种IR，需要运行在NV运行时引擎之上，这与java字节码运行在JVM上类似，具体来说NV运行时引擎接收PTX，并在运行时将PTX进一步编译成可以运行在gpu核心上的机器指令；将设备端代码编译成PTX IR的编译方式也被成为半编译方式；<br><br>
nv运行时引擎可以理解成gpu的操作系统，可以管理gpu的资源，就像一般的操作系统可以管理cpu及内存资源一样；nv运行时引擎一般放在gpu驱动程序中，插入gpu板卡时自动安装，gpu驱动程序可以让cpu意识到gpu的存在，并能让cpu轻松访问gpu资源；<br><br>
cuda程序的一般结构为：1）使用cudaMalloc()分配gpu端内存：虽然这个函数是在分配设备端内存，但这个函数确是一个主机端API，具体来说，cpu询问nv运行时引擎是否可以分配指定大小的gpu内存，如果可以，则返回gpu端首地址的指针，该指针用cpu端变量保存；
2）使用cudaMemoryCopy()将cpu内存中的数据拷贝到gpu内存中：需要明确的一点是，cpu和gpu不共享任何的电子部件，gpu只是一种外插卡，cpu的内存在主板上，而gpu的内存在gpu板卡上；该API依然是主机端API；3）启动并执行设备端函数（下一节详述）；4）使用cudaMemoryCopy()将gpu内存中的计算结果拷贝到cpu内存中；5）使用cudaFree()释放gpu内存；具体到运行时，cuda程序的运行流程除了拷贝数据外，还需要将PTX指令从cpu端传到gpu端；<br><br>
#### CUDA编程
cuda编程模型是一种主机/设备编程模型，主机/设备编程模型意味着gpu编程和cpu编程是同时存在的，一个程序里既有cpu指令又有gpu指令，而且程序的入口是cpu端指令，主机(cpu)向设备(gpu)发出类似于协处理器类型的指令，在设备执行运算期间，主机并不知道设备在干什么，设备所有的指令执行完成后，主机可以获取执行结果；<br><br>
gpu的核函数是为每个线程编写的，核函数的逻辑即是每个线程需要执行的指令逻辑，程序员是以线程为单位为gpu编写程序的；在任何时候执行的线程数量都不能少于32个（32个线程称为一个线程束），
因此线程束是cuda程序的执行单位，但cuda程序员一般不感知线程束的存在（除非程序员要编写PTX汇编程序），nvcc编译器帮程序员完成线程到线程束的转换，cuda程序员需要关心的是核函数的具体逻辑以及以何种规模（网格size和线程块size）启动核函数，网格里的所有线程都会执行核函数逻辑，但每个线程由于有不同的blockIdx和threadIdx，
因此可以处理不同的数据（由程序员定义处理哪些数据）；< br><br>
网格是以一维、二维或者三维方式组织起来的线程块，这些线程块由硬件编号并传递给核函数，其中gridDim指明网格在各个维度上的大小，blockIdx指明某个线程块在网格中的索引位置；每个线程块是以一维、二维或者三维方式组织起来的线程，这些线程也是由硬件编号并传递给核函数，不同线程块内的线程之间的编号互相独立，blockDim指明该线程块中的线程维度，threadIdx指明线程在该线程块中的索引位置；
gpu并行编程的核心就是程序员可以以一维、二维或者三维的方式组织线程，而每个线程可以通过硬件以极地的开销获取gridDim、blockIdx、blockDim以及threadIdx变量，获取这些变量相当于在cpu中执行一重（对应一维网格）、二重（对应二位网格）或者三重（对应三维网格）循环，即gpu可以以极地的开销获得一重、二重或者三重循环，
每个线程根据gridDim、blockIdx、blockDim以及threadIdx即知道自己该对哪些数据进行计算（每个线程负责计算不同的数据），因此核函数标配的一个步骤则是根据gridDim、blockIdx、blockDim以及threadIdx得到一个独一无二的index，程序员负责将这个index与相应的数据和运算逻辑关联起来；<br><br>
影响cuda程序性能的因素主要有：1）PCIe总线的吞吐量：PCIe x16向下兼容x8/x4/x1，同一总线上可以连接gpu、声卡、网卡等外设，PCIe总线的峰值吞吐量一般可以达到几到十几GBPS；cpu和gpu之间的数据传输速度由主板、CPU、GPU中较小的决定，三者都要支持某一总线速度才可以；
2）全局内存总线带宽：gpu全局内存的峰值吞吐量可以达到几十到几百GBPS，除了全局内存外，gpu还有L1和L2高速缓存，其中L2为末级缓存（直接与全局内存相连），所有核心共享，一般为几兆大小，但速度极快；L1由同一SM里的多个线程共享，一般为几十KB；
3）计算能力：编译选项里可以指定不同的计算能力(cc)，cc的可选值有2.x(Fermi系列)、3.x(Kepler系列)、5.x(Maxwell系列)、6.x(Pascal)系列、7.x(Volta系列)，指定了某个cc后，编译器就使用该cc内的编译指令编译cuda代码，每次计算能力的迭代更新都会引入一些新的指令，但低版本的cc编译的程序可以运行在高版本的gpu中；4）共享内存、寄存器、SM等对性能的影响（[Nvidia GPU硬件理解]()中祥述）<br><br>
#### 总结
本文总结性地讲解了cuda编程的原理，没有涉及到代码，也没有涉及到更多的细节，需要指出的是，如果想要获得极致的cuda程序性能，必须对目标gpu的硬件结构和参数有清楚的了解，因为cuda程序的设计很大程度上的依赖gpu的硬件，比如如何选择合适的网格及线程块大小？如何使用共享内存提升程序性能？[Nvidia GPU硬件理解]()中讲解了nv gpu硬件相关知识；
除此之外，不断的尝试并测量程序的运行时间也是cuda程序开发中不可缺少的（并且痛苦的）环节，可以使用诸如cuda计算器的工具辅助我们优化性能；（完）<br><br>
