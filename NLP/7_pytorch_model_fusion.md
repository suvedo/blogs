[*<<返回主页*](../index.md)<br><br>
**本文为作者原创，转载请注明出处**<br>
### 使用pytorch融合多模型结果
本文讲解如何使用pytorch融合多模型结果；<br><br>
#### 问题背景
在工作中优化一个二分类问题，针对这个二分类问题有多个模型（每个模型的特征和模型结构有差别）输出多个结果，每个结果均是一个(0, 1)之间的浮点数；融合模型的任务是为每个基模型找一个权重，对多个基模型的结果加权平均；一开始由于基模型数量比较少（2~3个），我们直接使用遍历权重的方法，即取步长为0.01、范围为(0， 1），遍历权重的所有可能值，选取一个最优的权重组合，权重选取的标准是eer(equal error rate，等错误率)最小；如果只有两个基模型，计算复杂度是100，三个基模型时，计算复杂度是100 x 100 = 10000，
由此可见，计算复杂度随基模型的数量指数增加，当模型数量较多时，需要一天甚至几天才能找到最优值（运行时间跟数据量大小也有关系）；很显然遍历权重的方法是一种暴力且比较粗糙的办法，而目前主流的深度学习框架都可以自动计算梯度和优化参数，因此可以使用深度学习框架完成各基模型权重的优化，在本任务中不用考虑部署的问题，因此选用用户更加友好的pytorch作为目标框架；<br><br>
#### 解决方案
基模型权重学习本质上是一个简单的线性问题，但与线性问题不太一样的地方是需要保证权重的和为1，因此需要对参数进行归一化，假设有n个基模型，模型得分分别为(X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>)，模型权重分别为(w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>)，权重归一化后为w<sub>i</sub>/(w<sub>1</sub>+w<sub>2</sub>+ ... +w<sub>n</sub>)(i = 1,2, ..., n)，归一化后的权重与模型得分做矩阵乘法即可得到融合模型的得分；
使用权重归一化的好处是权重可以取任意的正数，不必局限在(0, 1)之间以及和为1；<br><br>
融合模型定义完成之后就可以定义模型的loss和优化方法，在<b>问题背景</b>中提到的办法其实是将eer作为loss，按道理融合模型的loss也可以使用eer，但似乎没看到哪个机器学习模型的loss是使用eer的，而且pytorch也不支持eer loss，所以放弃使用eer作为loss，但依然可以使用eer作为验证集的metrics；由于本问题是分类问题，自然而然的想到使用负对数损失函数，当然也可以使用mse；优化方法使用最简单的sgd即可；<br><br>
#### 代码细节
代码地址：[https://github.com/suvedo/model_fusion](https://github.com/suvedo/model_fusion)<br><br>
运行sh run.sh即可训练模型权重，训练相关的配置在config.py中，eval_metrics可以指定验证的metrics，支持eer或者auc，eer和auc的计算函数分别对应util.py中的cal_eer()和cal_auc()；配置do_early_stop是否使用早停，min_eval_impr配置最小的metric提升量，提升量小于该值表示这一轮的训练过拟合；training_loss指定loss，目前支持负对数(nll)和均方误差(mse)；<br><br>
模型的定义和训练在linear_model.py中，另外在util.py中还定义了一个训练数据和验证数据的生成器DataIter；<br><br>
#### 总结
从这个任务可以看出，pytorch等深度学习框架其实不止针对深度学习，只要我们能用pytorch支持的op或运算符将我们的任务正确的表示出来（包括模型和loss），即可以使用pytorch等框架的自动求导和数值优化能力帮助我们优化我们的任务参数，从这个角度来讲，pytorch等深度学习框架可以理解成一个基于梯度的数值优化框架，与matlab等商业工具类似；但我们日常的任务并不只是训练出模型参数就终止了，还需要对模型进行部署、线上服务等，因此如何高效的部署模型和前向计算是深度学习框架需要考虑的一个重要问题；（完）<br><br>
